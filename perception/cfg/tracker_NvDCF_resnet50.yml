%YAML:1.0
################################################################################
# SPDX-FileCopyrightText: Copyright (c) 2020-2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
################################################################################
# Document begins
---
BaseConfig:
  minDetectorConfidence: 0.75  # If the confidence of a detector bbox is lower than this, then it won't be considered for tracking

TargetManagement:
  enableBboxUnClipping: 1   # In case the bbox is likely to be clipped by image border, unclip bbox
  maxTargetsPerStream: 20  # Max number of targets to track per stream. Recommended to set >10. Note: this value should account for the targets being tracked in shadow mode as well. Max value depends on the GPU memory capacity

  # [Creation & Termination Policy]
  minIouDiff4NewTarget: 0.4   # If the IOU between the newly detected object and any of the existing targets is higher than this threshold, this newly detected object will be discarded.
  minTrackerConfidence: 0.6   # If the confidence of an object tracker is lower than this on the fly, then it will be tracked in shadow mode. Valid Range: [0.0, 1.0]
  probationAge: 3 # If the target's age exceeds this, the target will be considered to be valid.
  maxShadowTrackingAge: 50  # Max length of shadow tracking. If the shadowTrackingAge exceeds this limit, the tracker will be terminated.
  earlyTerminationAge: 1   # If the shadowTrackingAge reaches this threshold while in TENTATIVE period, the target will be terminated prematurely.

DataAssociator:
  dataAssociatorType: 0 # the type of data associator among { DEFAULT= 0 }
  associationMatcherType: 1 # the type of matching algorithm among { GREEDY=0, GLOBAL=1 }
  checkClassMatch: 1  # If checked, only the same-class objects are associated with each other. Default: true

  # [Association Metric: Thresholds for valid candidates]
  minMatchingScore4Overall: 0.1   # Min total score 0.0
  minMatchingScore4SizeSimilarity: 0.2  # Min bbox size similarity score 0.6
  minMatchingScore4Iou: 0.0       # Min IOU score 0.0
  minMatchingScore4VisualSimilarity: 0.2  # Min visual similarity score 0.7
  # minMatchingScore4ReidSimilarity: 0.4  # Min Reid similarity score 0.7

  # [Association Metric: Weights]                                                                                                                                                                                                                                                                                                                                                           
  # matchingScoreWeight4ReidSimilarity: 0.6  
  matchingScoreWeight4VisualSimilarity: 0.6  # Weight for the visual similarity (in terms of correlation response ratio)
  matchingScoreWeight4SizeSimilarity: 0.3    # Weight for the Size-similarity score
  matchingScoreWeight4Iou: 0.1   # Weight for the IOU score

StateEstimator:
  stateEstimatorType: 2  # the type of state estimator among { DUMMY=0, SIMPLE=1, REGULAR=2 }

  # [Dynamics Modeling]
  processNoiseVar4Loc: 16.0    # Process noise variance for bbox center
  processNoiseVar4Size: 16.0   # Process noise variance for bbox size
  processNoiseVar4Vel: 0.6    # Process noise variance for velocity
  measurementNoiseVar4Detector: 14.0    # Measurement noise variance for detector's detection
  measurementNoiseVar4Tracker: 16.0    # Measurement noise variance for tracker's localization

VisualTracker:
  visualTrackerType: 1 # the type of visual tracker among { DUMMY=0, NvDCF=1 }

  # [NvDCF: Feature Extraction]
  useColorNames: 1     # Use ColorNames feature
  useHog: 1            # Use Histogram-of-Oriented-Gradient (HOG) feature
  featureImgSizeLevel: 3  # Size of a feature image. Valid range: {1, 2, 3, 4, 5}, from the smallest to the largest
  featureFocusOffsetFactor_y: -0.2  # The offset for the center of hanning window relative to the feature height. 
                                    # The center of hanning window would move by 
                                    # (featureFocusOffsetFactor_y*featureMatSize.height) in vertical direction

  # [NvDCF: Correlation Filter]
  filterLr: 0.075 # learning rate for DCF filter in exponential moving average. Valid Range: [0.0, 1.0]
  filterChannelWeightsLr: 0.1 # learning rate for the channel weights among feature channels. Valid Range: [0.0, 1.0]
  gaussianSigma: 0.75 # Standard deviation for Gaussian for desired response when creating DCF filter [pixels]

TrajectoryManagement:
  useUniqueID: 0   # Use 64-bit long Unique ID when assignining tracker ID. Default is [true]
  enableReAssoc: 1    # Enable Re-Assoc
  minMatchingScore4Overall: 0.5    # min matching score for overall
  minTrackletMatchingScore: 0.4644    # min tracklet similarity score for re-assoc
  matchingScoreWeight4TrackletSimilarity: 0.8    # weight for tracklet similarity score
  minTrajectoryLength4Projection: 15    # min trajectory length required to make projected trajectory
  prepLength4TrajectoryProjection: 30    # the length of the trajectory during which the state estimator is updated to make projections
  trajectoryProjectionLength: 94    # the length of the projected trajectory
  maxAngle4TrackletMatching: 180    # max angle difference for tracklet matching [degree]
  minSpeedSimilarity4TrackletMatching: 0.0967    # min speed similarity for tracklet matching
  minBboxSizeSimilarity4TrackletMatching: 0.4577    # min bbox size similarity for tracklet matching
  maxTrackletMatchingTimeSearchRange: 100    # the search space in time for max tracklet similarity
  trajectoryProjectionProcessNoiseScale: 0.0100    # trajectory projector's process noise scale w.r.t. state estimator
  trajectoryProjectionMeasurementNoiseScale: 100    # trajectory projector's measurement noise scale w.r.t. state estimator
  trackletSpacialSearchRegionScale: 0.5 # 0.2598    # the search region scale for peer tracklet

ReID:
  reidType: 0  # 2  # The type of reid among { DUMMY=0, DEEP=1 }

  # [Reid Network Info]
  batchSize: 100
  workspaceSize: 1000
  reidFeatureSize: 256  # Resnet: 256, Transformer: 768
  reidHistorySize: 100
  inferDims: [3, 256, 196]  # Resnet: [3, 256, 128], Transformer: [3, 384, 128]
  networkMode: 2
  addFeatureNormalization: 0
  outputReidTensor: 0       # 1: output reid tensor

  # [Input Preprocessing]
  inputOrder: 0
  colorFormat: 0
  offsets: [87.21, 91.8, 93.585] # [0.342, 0.360, 0.367]
  netScaleFactor: 0.0039215697906911373
  keepAspc: 1
  # [Paths and Names]
  inputBlobName: "images"       # Reid network input layer name
  outputBlobName: "features"    # Reid network output layer name
  onnxFile: "/opt/storage/models/reid/resnet50_pilar_11cam_196x256.onnx"
  modelEngineFile: "/opt/storage/models/reid/resnet50_pilar_11cam_196x256_b20_fp16_dev1.engine"
